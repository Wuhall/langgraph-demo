{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "è‡ªå®šä¹‰çŠ¶æ€"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Annotated\n",
    "\n",
    "from langchain_tavily import TavilySearch\n",
    "from langchain_core.tools import tool\n",
    "from typing_extensions import TypedDict\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START, END\n",
    "from langgraph.graph.message import add_messages\n",
    "from langgraph.prebuilt import ToolNode, tools_condition\n",
    "\n",
    "from langgraph.types import Command, interrupt\n",
    "\n",
    "from llm_layer import llm\n",
    "\n",
    "'''è‡ªå®šä¹‰çŠ¶æ€ï¼Œæ·»åŠ nameå’Œbirthdayå±žæ€§'''\n",
    "class State(TypedDict):\n",
    "    messages: Annotated[list, add_messages]\n",
    "    name: str\n",
    "    birthday: str\n",
    "\n",
    "graph_builder = StateGraph(State)\n",
    "\n",
    "'''æ›´æ–°å·¥å…·å†…éƒ¨çŠ¶æ€'''\n",
    "@tool\n",
    "# è¯·æ³¨æ„ï¼Œç”±äºŽæˆ‘ä»¬æ­£åœ¨ç”Ÿæˆç”¨äºŽçŠ¶æ€æ›´æ–°çš„ToolMessageï¼Œå› æ­¤æˆ‘ä»¬é€šå¸¸éœ€è¦ç›¸åº”å·¥å…·è°ƒç”¨çš„IDã€‚\n",
    "# æˆ‘ä»¬å¯ä»¥ä½¿ç”¨LangChainçš„InjectedToolCallIdæ¥è¡¨ç¤ºæ­¤å‚æ•°ä¸åº”åœ¨å·¥å…·çš„æ¨¡å¼ä¸­å‘æ¨¡åž‹å…¬å¼€ã€‚\n",
    "def human_assistance(\n",
    "    name: str, birthday: str, tool_call_id: Annotated[str, InjectedToolCallId]\n",
    ") -> str:\n",
    "    \"\"\"Request assistance from a human.\"\"\"\n",
    "    human_response = interrupt(\n",
    "        {\n",
    "            \"question\": \"Is this correct?\",\n",
    "            \"name\": name,\n",
    "            \"birthday\": birthday,\n",
    "        },\n",
    "    )\n",
    "    # If the information is correct, update the state as-is.\n",
    "    if human_response.get(\"correct\", \"\").lower().startswith(\"y\"):\n",
    "        verified_name = name\n",
    "        verified_birthday = birthday\n",
    "        response = \"Correct\"\n",
    "    # Otherwise, receive information from the human reviewer.\n",
    "    else:\n",
    "        verified_name = human_response.get(\"name\", name)\n",
    "        verified_birthday = human_response.get(\"birthday\", birthday)\n",
    "        response = f\"Made a correction: {human_response}\"\n",
    "\n",
    "    # This time we explicitly update the state with a ToolMessage inside\n",
    "    # the tool.\n",
    "    state_update = {\n",
    "        \"name\": verified_name,\n",
    "        \"birthday\": verified_birthday,\n",
    "        \"messages\": [ToolMessage(response, tool_call_id=tool_call_id)],\n",
    "    }\n",
    "    # We return a Command object in the tool to update our state.\n",
    "    return Command(update=state_update)\n",
    "\n",
    "tool = TavilySearch(max_results=2)\n",
    "tools = [tool, human_assistance]\n",
    "llm_with_tools = llm.bind_tools(tools)\n",
    "\n",
    "def chatbot(state: State):\n",
    "    message = llm_with_tools.invoke(state[\"messages\"])\n",
    "    # Because we will be interrupting during tool execution,\n",
    "    # we disable parallel tool calling to avoid repeating any\n",
    "    # tool invocations when we resume.\n",
    "    assert len(message.tool_calls) <= 1\n",
    "    return {\"messages\": [message]}\n",
    "\n",
    "graph_builder.add_node(\"chatbot\", chatbot)\n",
    "\n",
    "tool_node = ToolNode(tools=tools)\n",
    "graph_builder.add_node(\"tools\", tool_node)\n",
    "\n",
    "graph_builder.add_conditional_edges(\n",
    "    \"chatbot\",\n",
    "    tools_condition,\n",
    ")\n",
    "graph_builder.add_edge(\"tools\", \"chatbot\")\n",
    "graph_builder.add_edge(START, \"chatbot\")\n",
    "\n",
    "\n",
    "'''ç¼–è¯‘graph'''\n",
    "memory = MemorySaver()\n",
    "\n",
    "graph = graph_builder.compile(checkpointer=memory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Can you look up when LangGraph was released? When you have the answer, use the human_assistance tool for review.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': \"I'll help you search for information about LangGraph's release and then get it reviewed.\\n\\nFirst, let me search for LangGraph's release date:\", 'type': 'text'}, {'id': 'toolu_01NfXxyUKesZN8BgQLqU7RG2', 'input': {'query': 'When was LangGraph released launch date'}, 'name': 'tavily_search', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search (toolu_01NfXxyUKesZN8BgQLqU7RG2)\n",
      " Call ID: toolu_01NfXxyUKesZN8BgQLqU7RG2\n",
      "  Args:\n",
      "    query: When was LangGraph released launch date\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"When was LangGraph released launch date\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"Customize state - langchain-ai.lang.chat\", \"url\": \"https://langchain-ai.lang.chat/langgraph/tutorials/get-started/5-customize-state/\", \"content\": \"Prompt the chatbot to look up the \\\"birthday\\\" of the LangGraph library and direct the chatbot to reach out to the `human_assistance` tool once it has the required information. Then, I'll use the human_assistance tool for review.\\\", 'type': 'text'}, {'id': 'toolu_01JoXQPgTVJXiuma8xMVwqAi', 'input': {'query': 'LangGraph release date'}, 'name': 'tavily_search_results_json', 'type': 'tool_use'}] \\\\n\\\\nGiven this information, I'll use the human_assistance tool to review and potentially provide more accurate information about LangGraph's initial release date.\\\", 'type': 'text'}, {'id': 'toolu_01JDQAV7nPqMkHHhNs3j3XoN', 'input': {'name': 'Assistant', 'birthday': '2023-01-01'}, 'name': 'human_assistance', 'type': 'tool_use'}] \\\\n\\\\nGiven this information, I'll use the human_assistance tool to review and potentially provide more accurate information about LangGraph's initial release date.\\\", 'type': 'text'}, {'id': 'toolu_01JDQAV7nPqMkHHhNs3j3XoN', 'input': {'name': 'Assistant', 'birthday': '2023-01-01'}, 'name': 'human_assistance', 'type': 'tool_use'}]\", \"score\": 0.6892434, \"raw_content\": null}, {\"title\": \"Releases Â· langchain-ai/langgraph - GitHub\", \"url\": \"https://github.com/langchain-ai/langgraph/releases\", \"content\": \"Releases Â· langchain-ai/langgraph Â· GitHub *   fix(langgraph): remove deprecated `output` usage in favor of `output_schema` (#5095) *   Remove Checkpoint.writes (#4822) *   Remove old checkpoint test fixtures (#4814) *   fix(langgraph): remove deprecated `output` usage in favor of `output_schema` (#5095) *   Remove support for node reading a single managed value *   Remove Checkpoint.writes (#4822) *   Remove Checkpoint.pending_sends (#4820) *   Remove old checkpoint test fixtures (#4814) Changes since checkpoint==2.0.26 *   langgraph-checkpoint 2.1.0 *   Preparation for 0.5 release: langgraph-checkpoint (#5124) *   Remove Checkpoint.writes *   Remove Checkpoint.pending_sends *   Remove Checkpoint.writes (#4822) *   Remove Checkpoint.pending_sends (#4820) *   Remove old checkpoint test fixtures (#4814) *   Remove postgres shallow checkpointer (#4813) *   Remove Checkpoint.writes *   Remove Checkpoint.pending_sends *   Remove old checkpoint test fixtures *   Remove postgres shallow checkpointer\", \"score\": 0.16963993, \"raw_content\": null}], \"response_time\": 1.44}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': 'Let me try another search to get more specific information:', 'type': 'text'}, {'id': 'toolu_018FJT2Q1tsvQucw4sPbqJyn', 'input': {'query': 'LangGraph first release announcement langchain', 'time_range': 'year'}, 'name': 'tavily_search', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  tavily_search (toolu_018FJT2Q1tsvQucw4sPbqJyn)\n",
      " Call ID: toolu_018FJT2Q1tsvQucw4sPbqJyn\n",
      "  Args:\n",
      "    query: LangGraph first release announcement langchain\n",
      "    time_range: year\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: tavily_search\n",
      "\n",
      "{\"query\": \"LangGraph first release announcement langchain\", \"follow_up_questions\": null, \"answer\": null, \"images\": [], \"results\": [{\"title\": \"LangChain Unveils LangGraph Studio: The First IDE for Agent Development\", \"url\": \"https://blockchain.news/news/langchain-unveils-langgraph-studio-the-first-ide-for-agent-development\", \"content\": \"# LangChain Unveils LangGraph Studio: The First IDE for Agent Development LangChain introduces LangGraph Studio, a specialized IDE for developing, visualizing, and debugging agentic applications, now available in open beta. LangChain Unveils LangGraph Studio: The First IDE for Agent Development LangChain has announced the launch of LangGraph Studio, the first Integrated Development Environment (IDE) specifically designed for agent development. LangGraph Studio aims to simplify the development process for LLM (Large Language Model) applications by providing a specialized environment for visualizing, interacting with, and debugging agentic applications. LangGraph Studio augments the development experience by allowing developers to visualize agent graphs, modify agent results, and interact with the state of the agent at any point in time.\", \"score\": 0.8282873, \"raw_content\": null}, {\"title\": \"LangGraph Release Week Recap - blog.langchain.com\", \"url\": \"https://blog.langchain.com/langgraph-release-week-recap/\", \"content\": \"See what we released for LangGraph.js and Python over the past few weeks to speed up development workflows and gain more control at every level of your graph. Over the past few weeks, we rolled out new features for both LangGraph.js and LangGraph Python, improving both low level workflows and prebuilt agents. Now you can cache the results of individual nodes in your LangGraph workflow, reducing redundant computation and speeding up execution. ðŸ”— Python docs | JS docs Deferred nodes are ideal for map-reduce, consensus, and agent collaboration workflows. As a nice bonus, check out these interactive docs that help you visualize react agent workflows. In addition to the above features introduced in both Python and JS, weâ€™ve also added a few improvements specifically on the JS side.\", \"score\": 0.38304168, \"raw_content\": null}], \"response_time\": 1.37}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': 'Based on my research, LangGraph appears to have been released recently, with major announcements and updates happening in early 2024. The LangGraph Studio IDE was recently announced, and there have been ongoing releases and updates. However, to ensure we have the most accurate information about the initial release date, let me request human assistance for review:', 'type': 'text'}, {'id': 'toolu_012TLmCYnBFc9eCWmM6MYwmJ', 'input': {'name': 'LangGraph', 'birthday': '2024-01-01'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_012TLmCYnBFc9eCWmM6MYwmJ)\n",
      " Call ID: toolu_012TLmCYnBFc9eCWmM6MYwmJ\n",
      "  Args:\n",
      "    name: LangGraph\n",
      "    birthday: 2024-01-01\n"
     ]
    }
   ],
   "source": [
    "'''prompt the chatbot'''\n",
    "user_input = (\n",
    "    \"Can you look up when LangGraph was released? \"\n",
    "    \"When you have the answer, use the human_assistance tool for review.\"\n",
    ")\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "events = graph.stream(\n",
    "    {\"messages\": [{\"role\": \"user\", \"content\": user_input}]},\n",
    "    config,\n",
    "    stream_mode=\"values\",\n",
    ")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "[{'text': 'Based on my research, LangGraph appears to have been released recently, with major announcements and updates happening in early 2024. The LangGraph Studio IDE was recently announced, and there have been ongoing releases and updates. However, to ensure we have the most accurate information about the initial release date, let me request human assistance for review:', 'type': 'text'}, {'id': 'toolu_012TLmCYnBFc9eCWmM6MYwmJ', 'input': {'name': 'LangGraph', 'birthday': '2024-01-01'}, 'name': 'human_assistance', 'type': 'tool_use'}]\n",
      "Tool Calls:\n",
      "  human_assistance (toolu_012TLmCYnBFc9eCWmM6MYwmJ)\n",
      " Call ID: toolu_012TLmCYnBFc9eCWmM6MYwmJ\n",
      "  Args:\n",
      "    name: LangGraph\n",
      "    birthday: 2024-01-01\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "Name: human_assistance\n",
      "\n",
      "Made a correction: {'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Thank you for the human assistance! I can now provide accurate information: LangGraph was released on January 17, 2024.\n"
     ]
    }
   ],
   "source": [
    "'''èŠå¤©æœºå™¨äººæ— æ³•è¯†åˆ«æ­£ç¡®çš„æ—¥æœŸ'''\n",
    "# æä¾›ä¸‹é¢çš„ä¿¡æ¯\n",
    "human_command = Command(\n",
    "    resume={\n",
    "        \"name\": \"LangGraph\",\n",
    "        \"birthday\": \"Jan 17, 2024\",\n",
    "    },\n",
    ")\n",
    "\n",
    "events = graph.stream(human_command, config, stream_mode=\"values\")\n",
    "for event in events:\n",
    "    if \"messages\" in event:\n",
    "        event[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''èŽ·å–çŠ¶æ€'''\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'configurable': {'thread_id': '1',\n",
       "  'checkpoint_ns': '',\n",
       "  'checkpoint_id': '1f05327a-6163-68ee-8008-6f7ce362b05f'}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''æ›´æ–°çŠ¶æ€'''\n",
    "graph.update_state(config, {\"name\": \"LangGraph (library)\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'LangGraph (library)', 'birthday': 'Jan 17, 2024'}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''æŸ¥çœ‹æ›´æ–°çš„å€¼'''\n",
    "snapshot = graph.get_state(config)\n",
    "\n",
    "{k: v for k, v in snapshot.values.items() if k in (\"name\", \"birthday\")}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "langgraph",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
